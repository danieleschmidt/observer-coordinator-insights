# CI/CD Pipeline for Observer Coordinator Insights
name: Continuous Integration

on:
  push:
    branches: [ main, develop, 'feature/**', 'hotfix/**' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 6 AM UTC
    - cron: '0 6 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Security and Quality Gates
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Python security check with bandit
        run: |
          pip install bandit[toml]
          bandit -r src/ -f json -o bandit-report.json || true

      - name: Upload security artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            trivy-results.sarif
            bandit-report.json
          retention-days: 30

  # Code Quality Analysis  
  quality-check:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install ruff mypy black isort pytest-cov

      - name: Run code formatting check
        run: |
          black --check src/ tests/
          isort --check-only src/ tests/

      - name: Run linting
        run: |
          ruff check src/ tests/ --output-format=github

      - name: Run type checking
        run: |
          mypy src/ --ignore-missing-imports

      - name: Upload quality artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-reports
          path: |
            quality_reports/
          retention-days: 30

  # Unit and Integration Tests
  test:
    name: Test Suite
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.11', '3.12']
        
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_oci
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install system dependencies
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-xdist pytest-benchmark

      - name: Set up test environment
        run: |
          cp .env.example .env.test
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_oci" >> .env.test
          echo "REDIS_URL=redis://localhost:6379/0" >> .env.test

      - name: Run database migrations
        run: |
          python -m alembic upgrade head
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_oci

      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --benchmark-skip
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_oci
          REDIS_URL: redis://localhost:6379/0

      - name: Run integration tests
        run: |
          pytest tests/integration/ -v --cov=src --cov-append --cov-report=xml --benchmark-skip
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_oci
          REDIS_URL: redis://localhost:6379/0

      - name: Run performance benchmarks
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        run: |
          pytest tests/benchmarks/ -v --benchmark-only --benchmark-json=benchmark-results.json

      - name: Upload test coverage
        uses: codecov/codecov-action@v3
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            htmlcov/
            benchmark-results.json
            pytest-report.xml
          retention-days: 30

  # API Testing
  api-test:
    name: API Integration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_oci_api
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up test database
        run: |
          python -m alembic upgrade head
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_oci_api

      - name: Start API server
        run: |
          uvicorn src.api.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_oci_api
          REDIS_URL: redis://localhost:6379/0

      - name: Run API health check
        run: |
          curl -f http://localhost:8000/api/health || exit 1

      - name: Run API integration tests
        run: |
          pytest tests/api/ -v --api-url=http://localhost:8000

      - name: Generate OpenAPI documentation
        run: |
          curl http://localhost:8000/openapi.json > openapi.json

      - name: Upload API artifacts
        uses: actions/upload-artifact@v4
        with:
          name: api-documentation
          path: openapi.json
          retention-days: 30

  # Container Build and Scan
  build-container:
    name: Build Container
    runs-on: ubuntu-latest
    needs: [security-scan, quality-check, test]
    permissions:
      contents: read
      packages: write
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=sha-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push container image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: Run Trivy container scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-container.sarif'

      - name: Upload container scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-container.sarif'

  # End-to-End Testing
  e2e-test:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [build-container]
    if: github.event_name == 'pull_request' || github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Compose
        run: |
          docker-compose -f docker-compose.test.yml up -d
          sleep 30

      - name: Run E2E tests
        run: |
          docker-compose -f docker-compose.test.yml run --rm e2e-tests

      - name: Collect logs
        if: always()
        run: |
          mkdir -p logs
          docker-compose -f docker-compose.test.yml logs > logs/docker-compose.log

      - name: Upload E2E artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            logs/
            tests/e2e/reports/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.test.yml down -v

  # Performance Testing
  performance-test:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [build-container]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Start test environment
        run: |
          docker-compose -f docker-compose.perf.yml up -d
          sleep 30

      - name: Run performance tests
        run: |
          k6 run tests/performance/load-test.js --out json=performance-results.json

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: performance-results.json
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.perf.yml down -v

  # Deployment to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-container, api-test]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster oci-staging \
            --service oci-api \
            --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable \
            --cluster oci-staging \
            --services oci-api

      - name: Run smoke tests
        run: |
          python tests/smoke/staging_smoke_test.py

  # Production Deployment (Manual Approval Required)
  deploy-production:
    name: Deploy to Production  
    runs-on: ubuntu-latest
    needs: [build-container, e2e-test, performance-test]
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Blue-Green deployment
        run: |
          # Deploy to blue environment first
          aws ecs update-service \
            --cluster oci-production-blue \
            --service oci-api \
            --force-new-deployment
          
          # Wait for deployment to stabilize
          aws ecs wait services-stable \
            --cluster oci-production-blue \
            --services oci-api

      - name: Run production smoke tests
        run: |
          python tests/smoke/production_smoke_test.py --environment=blue

      - name: Switch traffic to blue environment
        run: |
          # Update load balancer target group
          aws elbv2 modify-listener \
            --listener-arn ${{ secrets.PROD_LISTENER_ARN }} \
            --default-actions file://blue-environment-config.json

      - name: Monitor deployment
        run: |
          # Monitor for 10 minutes
          python scripts/monitor_deployment.py --duration=600

      - name: Rollback on failure
        if: failure()
        run: |
          # Rollback to green environment
          aws elbv2 modify-listener \
            --listener-arn ${{ secrets.PROD_LISTENER_ARN }} \
            --default-actions file://green-environment-config.json

  # Release Management
  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: github.ref == 'refs/heads/main' && startsWith(github.event.head_commit.message, 'release:')
    permissions:
      contents: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Extract version from commit message
        id: version
        run: |
          VERSION=$(echo "${{ github.event.head_commit.message }}" | grep -oP 'release:\s*\K[\d.]+')
          echo "version=v$VERSION" >> $GITHUB_OUTPUT

      - name: Generate changelog
        run: |
          # Generate changelog since last tag
          git log $(git describe --tags --abbrev=0)..HEAD --pretty=format:"- %s" > CHANGELOG.md

      - name: Create release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ steps.version.outputs.version }}
          release_name: Release ${{ steps.version.outputs.version }}
          body_path: CHANGELOG.md
          draft: false
          prerelease: false

  # Notification
  notify:
    name: Notify Team
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()
    steps:
      - name: Notify Slack
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}