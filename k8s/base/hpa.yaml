# Horizontal Pod Autoscaler for Observer Coordinator Insights API
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: oci-api-hpa
  namespace: observer-coordinator-insights
  labels:
    app.kubernetes.io/name: observer-coordinator-insights
    app.kubernetes.io/component: hpa
    app.kubernetes.io/part-of: neuromorphic-analytics
    app.kubernetes.io/managed-by: kustomize
  annotations:
    description: "Horizontal Pod Autoscaler for API server based on CPU, memory, and custom metrics"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: oci-api
  
  minReplicas: 3
  maxReplicas: 20
  
  # Scaling behavior configuration
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutes
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Min
    
    scaleUp:
      stabilizationWindowSeconds: 60   # 1 minute
      policies:
        - type: Percent
          value: 100
          periodSeconds: 60
        - type: Pods
          value: 4
          periodSeconds: 60
      selectPolicy: Max
  
  metrics:
    # CPU utilization metric
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    
    # Memory utilization metric
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    
    # Custom metric: API request rate
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
          selector:
            matchLabels:
              app.kubernetes.io/name: observer-coordinator-insights
        target:
          type: AverageValue
          averageValue: "100"
    
    # Custom metric: Queue depth (for clustering jobs)
    - type: Pods
      pods:
        metric:
          name: clustering_job_queue_depth
          selector:
            matchLabels:
              app.kubernetes.io/name: observer-coordinator-insights
        target:
          type: AverageValue
          averageValue: "10"
    
    # External metric: Load balancer latency (if available)
    - type: External
      external:
        metric:
          name: aws_alb_target_response_time
          selector:
            matchLabels:
              load_balancer: oci-alb
        target:
          type: Value
          value: "200m"  # 200ms

---
# Vertical Pod Autoscaler for resource recommendations
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: oci-api-vpa
  namespace: observer-coordinator-insights
  labels:
    app.kubernetes.io/name: observer-coordinator-insights
    app.kubernetes.io/component: vpa
    app.kubernetes.io/part-of: neuromorphic-analytics
    app.kubernetes.io/managed-by: kustomize
  annotations:
    description: "Vertical Pod Autoscaler for resource recommendations"
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: oci-api
  
  updatePolicy:
    updateMode: "Off"  # Only provide recommendations, don't auto-apply
  
  resourcePolicy:
    containerPolicies:
      - containerName: api-server
        minAllowed:
          cpu: 100m
          memory: 512Mi
        maxAllowed:
          cpu: 2000m
          memory: 4Gi
        controlledResources: ["cpu", "memory"]
        controlledValues: RequestsAndLimits
      
      - containerName: log-forwarder
        minAllowed:
          cpu: 10m
          memory: 32Mi
        maxAllowed:
          cpu: 100m
          memory: 128Mi
        controlledResources: ["cpu", "memory"]
        controlledValues: RequestsAndLimits